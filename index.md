---
layout: default
title: Home
---

<section>
  <h2>About Me</h2>
  <p>
    I'm currently learning Python and diving deep into large language models (LLMs). I run over 30 models locally using LM Studio and design evaluation rubrics to test prompt behavior across domains like math, storytelling, science, and research.
  </p>
  <p>
    My goal is to build thoughtful AI tools that go beyond hype—and share what I learn along the way.
  </p>
</section>

<section>
  <h2>Blog</h2>

  <div class="blog">
    <h3><a href="/blog/">Lab Notes</a></h3>
    <p>Here you’ll find updates, experiments, and commentary on my prompt engineering journey.</p>
  </div>

  <!-- Future blog links will be auto-generated or manually added here -->
</section>

<section>
  <h2>Projects</h2>

  <div class="project">
    <h3><a href="https://github.com/chicanoinparis/llm-prompt-eval-lab">LLM Prompt Evaluation Lab</a></h3>
    <p>A collection of test prompts run through 30+ local models, with performance notes, screenshots, and a rubric developed across multiple use cases.</p>
  </div>

  <div class="project">
    <h3><a href="https://github.com/chicanoinparis/prompt-cookbook">Prompt Cookbook</a></h3>
    <p>A growing library of tested prompts for summarization, instruction following, creativity, and more—optimized for OpenAI, Claude, DeepSeek, and others.</p>
  </div>
</section>

<section>
  <h2>Contact</h2>
  <p>Email me at: <a href="mailto:rudy@simplesolutions.technology">rudy@simplesolutions.technology</a></p>
  <p>GitHub: <a href="https:
