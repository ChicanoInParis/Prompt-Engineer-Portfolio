Model Name,Average Accuracy
microsoft/phi-4-reasoning-plus,4.714285714285714
google/gemma-3-27b,4.714285714285714
qwen/qwen3-32b,4.714285714285714
ibm/granite-3.1-8b,4.571428571428571
ibm/granite-3.2-8b,4.571428571428571
qwen/qwen3-8b,4.571428571428571
qwen/qwen2.5-coder-32b,4.571428571428571
qwen/qwen3-14b,4.571428571428571
google/gemma-2-9b,4.428571428571429
qwen/qwen2.5-coder-14b,4.285714285714286
google/gemma-2-27b,4.285714285714286
openchat-3.6-8b-20240522-imat,4.214285714285714
google/gemma-3-4b,4.214285714285714
microsoft/phi-4,4.142857142857143
mistralai/devstral-small-2505,4.142857142857143
deepseek/deepseek-r1-0528-qwen3-8b,4.071428571428571
google/gemma-3-12b,4.0
yi-1.5-6b-chat,4.0
mistralai/codestral-22b-v0.1,3.9285714285714284
qwen/qwq-32b,3.857142857142857
mistralai/mistral-nemo-instruct-2407,3.7142857142857144
microsoft/phi-4-mini-reasoning,3.7142857142857144
mistralai/mathstral-7b-v0.1,3.5714285714285716
meta/llama-3.3-70b,3.5714285714285716
mistralai/mistral-7b-instruct-v0.3,3.357142857142857
deepseek-coder-33b-instruct,3.357142857142857
airoboros-l2-70b-2.1,3.2857142857142856
mythomax-l2-13b,3.0714285714285716
nous-hermes-2-mixtral-8x7b-sft,3.0714285714285716
deepseek-math-7b-instruct,2.4285714285714284
sciphi-mistral-7b-32k,2.0714285714285716
