# ðŸ§ª LLM Accuracy Benchmark (Zero vs One Shot)

This is a personal benchmark comparing 31 local LLMs across a variety of tasks using zero-shot and one-shot prompts. Each model was scored from 0â€“5 in categories like:

- Math
- Coding
- Logic
- Ambiguity
- Creativity
- Medical knowledge
- Error handling

## ðŸ“Š What's Inside

- `LLM_analysis.ipynb` â€“ Python notebook using pandas + matplotlib
- `LLM-zero-one-shot.csv` â€“ Raw scoring data
- `llm-accuracy-chart.png` â€“ (Optional) chart image

## ðŸ“– Blog Post

Read the full write-up here:  
ðŸ‘‰ [chicanoinparis.github.io â†’ LLM Blog Post](https://chicanoinparis.github.io/Prompt-Engineer-Portfolio/2025/06/19/my-first-dive.html)

---